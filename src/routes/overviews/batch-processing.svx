---
title: Batch Processing
blurb: |
    Executing workflows across collections of sounds and analyses.
tags: 
    - workflow
    - beginner
    - intermediate
---

<script>
    import CodeBlock from '$lib/components/CodeBlock.svelte';
    import Image from '$lib/components/Image.svelte';
    import { Tabs, TabList, TabPanel, Tab } from '$lib/components/tabs/tabs';
</script>

## Introduction
One of the major pain points working with machine learning and machine listening is that we often need to process and work on collections of sounds, slices or analyses. If you're familiar with a text-based programming language you'll be acquainted with the `for` or `while` loop, or a similar structure that can _iterate_ over a sequence or group of items.

For example, in Python we might do something like this:

<CodeBlock>

```py
instruments = ['drums', 'synth', 'guitar', 'saxophone']

for instrument in instruments:
    decompose(instrument)
```

</CodeBlock>

This would run the `decompose()` function on each `instrument` stored in the list called `instruments`. This type of programmatic control flow can be observed widely in text-based languages. Ultimately, this is the concept of processing things in _batches_.

Let's think about the same workflow in Max and PureData (we'll come to SuperCollider a bit later) which are both visual programming languages that inherently struggle with the idea of iteration and batch processing. How does one iterate? How does one instruct the program where to start and where to stop? What is the equivalent of the `instruments` list that holds multiple items that will be processed? The rest of this overview will dig into this and suggest some ways in which our programming workflows can accomodate the notion of processing multiple items.

## A Foundation

Without even addressing FluCoMa objects directly, it is relevant to remind ourselves of what forms batch processing already exists in Max, PD and SC.

Let's first take a look at the humble Max list and how it is useful. We'll start by making a small patch that adds two numbers together. 

<Image 
src='/examples/batch/add.png'
alt='A small patch to add two numbers together'
/>

This is fine. However, it is limited to adding two singular values together. If we want to use it to add two collections of numbers together, we would have to stream the values of two lists into the inlets, get the result and construct it back into a list. Another approach would be to copy this bit of patch multiple times and serve each copy with two single values.

<Image
src='/examples/batch/add-streams.png'
alt='Adding two lists together in Max using streams'
/>

We can avoid these kinds of workflows by instead using objects that deal with collections of items in a list natively.

<Image
src='/examples/batch/add-list.png'
alt='Using vexpr to add two lists together'
/>

The complexity of the patching hasn't increased greatly, and by replacing `+` with `vexpr` (vector expression), we can process entire lists of values. The patch will also still work with single value inputsÂ (scalars) making it much more flexible than what we had originally. While the patching itself is not too complicated, knowing about the existence of these objects and how they work is not greatly emphasised in the way visual programming is taught wich is often concerned entirely with _streams_ of scalar values. Furthermore, while this is just a toy example, it demonstrates that the notion of processing groups of things together is not the **first** and **most obvious** way to patch. SC has the benefit of being built on the SuperCollider language which offers a number of ways to deal with arrays of data already that are both efficient and sleek to use. Logical operators also are _overloaded_ in many cases, meaning the interface for adding two integers is roughly the same as adding two arrays of integers. For example:

<CodeBlock>

```js
(
// Add together two integers
z = 1;
x = 10;
(z + x).postln;
)

(
// Add together two lists
z = [1, 2, 3, 4];
x = [10, 20, 30, 40];
(z + x).postln;
)
```

</CodeBlock>

## Batch Processing

So how do we approach batch processing with the FluCoMa objects? No doubt, there will be scenarios where working with bundles of data, numerous slices or several audio files can be frustrating and hard to structure in the code. The next section will demonstrate a number of ways in which batch processing can be implemented in Max, SC and PD and attempt to show how our interfacescan interlock with the existing ones in your environment of choice. The explanation of particular objects and processes will be _in_ the patches and scripts themselves.

### Analysis of Segments

<Tabs>
<TabList>
    <Tab>Max</Tab>
    <Tab>PureData</Tab>
    <Tab>SuperCollider</Tab>
</TabList>
<TabPanel> <!-- Max -->
<a href='/examples/batch/batch-slicing.maxpat' download>Download Patch</a>
</TabPanel>

<TabPanel> <!-- Pure Data -->
<a href='/examples/batch/batch-slicing.pd' download>Download Patch</a>
</TabPanel> 

<TabPanel> <!-- SC -->
<a href='/examples/batch/batch-slicing.scd' download>Download Script</a>
</TabPanel> 
</Tabs>

In this example a single audio file is sliced into a collection of segments. Each segment will be analysed with an audio descriptor and the result for that segment will be stored in a [FluidDataSet](/reference/dataset).The example illustrates how one can iterate through several portions of the source buffer and use the segmentation result to control a process that only analyses specific portions of time in the source file.

The step-by-step workflow is as follows:

1. Segment a sound into small chunks.
2. Analyse each chunk using an audio descriptor.
3. Calculate the average of that audio descriptor for each chunk.
4. Store the average for each chunk in a [FluidDataSet](/reference/dataset).

### Decomposing Multiple Files

<Tabs>
<TabList>
    <Tab>Max</Tab>
    <Tab>PureData</Tab>
    <Tab>SuperCollider</Tab>
</TabList>
<TabPanel> <!-- Max -->
<a href='/examples/batch/batch-decomposition.maxpat' download>Download Patch</a>
</TabPanel>

<TabPanel> <!-- Pure Data -->
<a href='/examples/batch/batch-decomposition.pd' download>Download Patch</a>
</TabPanel> 

<TabPanel> <!-- SC -->
<a href='/examples/batch/batch-decomposition.scd' download>Download Script</a>
</TabPanel> 
</Tabs>

In this example a collection of audio files are processed as a batch using the [FluidHPSS](/reference/hpss) algorithm. Each decomposition is stored in a CCE specific container so that the results can be accessed later for audition or storage on disk. The example illustrates how a corpus might be processed as a whole in an automated way.

The step-by-step workflow is as follows:

1. Create a corpus of multiple audio files
2. Decompose each audio file into harmonic and percussive complnents using [FluidHPSS](/reference/hpss).
3. Store the results in some sort of _container_. This will depend on the CCE.

### Non-Blocking Processing

<Tabs>
<TabList>
    <Tab>Max</Tab>
    <Tab>PureData</Tab>
    <Tab>SC</Tab>
</TabList>
<TabPanel> <!-- Max -->
<div class='links'>
    <a href='/examples/batch/batch-slicing-threads.maxpat' download>Download Asynchronous Segment Analysis Patch</a>
    <a href='/examples/batch/batch-decomposition-threads.maxpat' download>Download Asynchronous Decomposition Patch</a>
</div>
</TabPanel>

<TabPanel> <!-- Pure Data -->
<div class='links'>
    <a href='/examples/batch/batch-slicing-threads.pd' download>Download Asynchronous Segment Analysis Patch </a>
    <a href='/examples/batch/batch-decomposition-threads.pd' download>Download Asynchronous Decomposition Patch</a>
</div>
</TabPanel> 

<TabPanel> <!-- SC -->
<div class='links'>
    <a href='/examples/batch/batch-slicing-threads.scd' download>Download Asynchronous Segment Analysis Script</a>
    <a href='/examples/batch/batch-decomposition-threads.scd' download>Download Asynchronous Decomposition Script</a>
</div>
</TabPanel>
</Tabs>

In the two examples above you may have noticed that whenever batch processing is started it seems to _freeze_ or _hang_ Max and PD. SuperCollider doesn't suffer the exact same issue because the language will continue to function even while the server is processing. However, the process that is executed is ultimately synchronous and working serially. Instead of always working syncrhonously FluCoMa objects can work in non-realtime individuated threads. This is sometimes referred to as _asynchronous_ or _non-blocking_ programming.

The benefit of making one's code asynchronous is that processes can be triggered and left to complete while other processes go on. This is a massive boon in a number of scenarios, albeit at the introduction of complexity in how we might expect analysis, decomposition and processes to start, finish and interact with each other.

The examples above illustrate how using `process()` and `wait` in SuperCollider and `@blocking 0` and `-blocking 0` in PD can allow us to trigger processes and _await_ the results of those processes.

<style>
    .links {
        display: flex;
        flex-direction: column;
        gap: 0.3em;
    }
</style>














