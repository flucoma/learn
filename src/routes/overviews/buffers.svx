---
title: Buffers in FluCoMa
blurb: |
    An attempt to explain our rationale for using buffers as an interface in FluCoMa
tags: 
    - interface
    - data
    - beginner
---
## Introduction
If you've been playing with the FluCoMa objects for a while now, you might be wondering why you have to use buffers (or arrays in PureData) so much. There are many reasons that FluCoMa leverages buffers as pivotal interface and design feature, and while they add complexity to certain workflows they also solve many problems at the same time. You also might be confused, especially as a Max user, and we'd like to try and rationalise our choices here and provide some insight on dealing with the buffer interface.

## Rationale

### Cross Platform and Environment Agnostic
FluCoMa has been initially developed for PureData, SuperCollider, Max and the Command Line. These environments are often capable languages for composing audio processing graphs but often exhibit their own quirks and idiosyncracies when dealing with collections of multi-dimensional data. In Max you might be used to using the family of `zl` objects, `coll` or `dict`. In PureData you're likely to have used `array`. SuperCollider is perhaps even more open-ended, depending on if you want to do data processing on the server or in the language. For machine learning, machine listening and decomposition we often a need a place to store data as an _input_, and somewhere else to store _outputs_ of a given process. With the wide range of idiomatic interfaces that already exist across the four platforms, using buffers and arrays helps to unify the FluCoMa interface This makes development across all the supported environments simpler because we don't have to write idiomatic code multiple times, rather, the _wrapper_ deals with this. In the future, we hope that this facilitates the development of additional environment wrappers, for example, [OpenFrameWorks](https://openframeworks.cc/).

### Fluidity of Workflow and Interface
Another reason to leverage buffers is that it allows you to capitalise on your programming skills in your environment of choice. Max users will perhaps be familiar with `poke~`, `peek~`, `waveform~` and `groove~`, which all offer ways to tap into the data you generate with machine learning as well as audition the results of decomposition processes. You aren't "locked in" to working with FluCoMa specific objects all of the time and instead can reach for workflows you already know that support accessing, modifying and transforming the contents of buffers and arrays. For example, [Timo Hoogland](https://www.timohoogland.com/) has used an [MLPClassifier](/reference/mlpclassifier) to create wavetables that are then accessed at audio rate in Max as a morphing synthesiser.

Also, the contents of a buffer can be written to disk, meaning you can store analysis, decomposition and segmentation results beyond the life of your environment of choice, as well as import the results between them freely between anywhere that can read an audio file.

### Efficiency and Overcoming Shortfalls
Buffers are also useful for overcoming the shortfalls of certain environments. We often deal with large collections of multi-dimensional data in machine learning and machine listening. This is potentially problematic if the environment imposes limitations on data that can be passed around. For example, Max lists are limited to 32767 items, whereas buffers are not constrained in the same way. In addition, buffers offer the possibility of having several channels of data meaning you can bundle more data into a single "container". This is often more efficient. SuperCollider and PureData users are perhaps more comfortable with the idea of an array holding both data and sound, so offering the buffer up as an interface for working with FluCoMa might feel more natural than say for a Max user.

## Workflows
Because buffers are used so ubiquitously throughout the FluCoMa toolkit it can be hard to reorientate your relationship to them in your creative coding environment of choice. One good way to start, is to imagine the `buffer~` `Buffer()` or `array` as a generic container or _grid_ that holds numbers. It is sort of like a spreadsheet in that regard where we can look on the x-axis (samples) and the y-axis (channels) to store or locate data.

### Audio Descriptors
All of the FluCoMa non-realtime audio descriptor objects in the toolkit use buffers or arrays as inputs and outputs. The input will contain a sound file, and the output will be a place to store the audio descriptors.

Let's look at this example of calculating the fundamental pitch using [FluidPitch](/reference/pitch).



### Decomposition
Objects that deal with decomposing sound in non-realtime will use buffers or arrays as inputs and outputs. The sound that you specify as the `source`, will be the input and depending on the object an output container will be specified.

**HPSS**

### Segmentation

**Noveltyslice**

### Dataset

**tobuffer and from buffer**

## Related Links

Audio Descriptors Video